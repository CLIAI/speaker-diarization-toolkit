#!/usr/bin/env python3
"""
speaker_samples - Voice sample extraction and management tool

Extract voice samples from audio files using transcript timing information.
Store samples with full provenance metadata for speaker enrollment.

Usage:
    # Extract samples from transcript
    speaker_samples extract --transcript file.json --speaker-label S1 --speaker-id alice audio.mp3

    # Output segment times as JSONL (for piping)
    speaker_samples segments --transcript file.json --speaker-label S1 audio.mp3

    # List stored samples
    speaker_samples list [person_id]

    # Show sample metadata
    speaker_samples info <person_id> <sample_id>

    # Remove samples
    speaker_samples remove <person_id> [--all] [--source pattern]

Environment:
    SPEAKERS_EMBEDDINGS_DIR - Storage location (default: ~/.config/speakers_embeddings)
"""

import argparse
import hashlib
import json
import os
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple

try:
    import yaml
    YAML_AVAILABLE = True
except ImportError:
    YAML_AVAILABLE = False

# Try to import consolidated transcript parsing
try:
    from speaker_detection_backends.transcript import (
        detect_transcript_format as _detect_transcript_format,
        get_available_speakers as _get_available_speakers,
        extract_segments_from_transcript as _extract_segments_from_transcript,
    )
    TRANSCRIPT_MODULE_AVAILABLE = True
except ImportError:
    TRANSCRIPT_MODULE_AVAILABLE = False

# ----------------------------------------------------------------------
# Configuration
# ----------------------------------------------------------------------

DEFAULT_DB_DIR = os.path.expanduser("~/.config/speakers_embeddings")
METADATA_VERSION = 2  # v2: Added b3sum, review fields


def get_db_dir() -> Path:
    """Get the speakers embeddings directory."""
    return Path(os.environ.get("SPEAKERS_EMBEDDINGS_DIR", DEFAULT_DB_DIR))


def get_samples_dir() -> Path:
    """Get the samples storage directory."""
    return get_db_dir() / "samples"


def get_speaker_samples_dir(speaker_id: str) -> Path:
    """Get samples directory for a specific speaker."""
    return get_samples_dir() / speaker_id


def ensure_speaker_samples_dir(speaker_id: str) -> Path:
    """Ensure speaker samples directory exists."""
    path = get_speaker_samples_dir(speaker_id)
    path.mkdir(parents=True, exist_ok=True)
    return path


# ----------------------------------------------------------------------
# Transcript Parsing
# ----------------------------------------------------------------------

def detect_transcript_format(data: Dict[str, Any]) -> str:
    """
    Detect transcript format from JSON structure.

    Returns:
        'assemblyai', 'speechmatics', or 'unknown'
    """
    # Use consolidated module if available
    if TRANSCRIPT_MODULE_AVAILABLE:
        return _detect_transcript_format(data)

    # Fallback implementation
    if "utterances" in data:
        return "assemblyai"
    if "results" in data and isinstance(data.get("results"), list):
        # Check for Speechmatics-style structure
        if data["results"] and "alternatives" in data["results"][0]:
            return "speechmatics"
        if data["results"] and "start_time" in data["results"][0]:
            return "speechmatics"
    return "unknown"


def get_available_speakers(data: Dict[str, Any]) -> List[str]:
    """Get list of speaker labels in transcript."""
    # Use consolidated module if available
    if TRANSCRIPT_MODULE_AVAILABLE:
        return _get_available_speakers(data)

    # Fallback implementation
    fmt = detect_transcript_format(data)
    speakers = set()

    if fmt == "assemblyai":
        for utt in data.get("utterances", []):
            if "speaker" in utt:
                speakers.add(utt["speaker"])
    elif fmt == "speechmatics":
        for item in data.get("results", []):
            if item.get("type") != "word":
                continue
            # Check top level
            if "speaker" in item:
                speakers.add(item["speaker"])
            # Check alternatives (Speechmatics with speaker ID)
            for alt in item.get("alternatives", []):
                if "speaker" in alt:
                    speakers.add(alt["speaker"])

    return sorted(speakers)


def extract_segments_from_transcript(
    data: Dict[str, Any],
    speaker_label: str,
    min_duration: float = 0.5,
    max_gap: float = 1.0,
) -> List[Dict[str, Any]]:
    """
    Extract time segments for a speaker from transcript.

    Args:
        data: Transcript JSON data
        speaker_label: Speaker label to extract
        min_duration: Minimum segment duration in seconds
        max_gap: Maximum gap to merge adjacent segments

    Returns:
        List of segment dicts with start, end, text
    """
    # Use consolidated module if available
    if TRANSCRIPT_MODULE_AVAILABLE:
        return _extract_segments_from_transcript(data, speaker_label, min_duration, max_gap)

    # Fallback implementation
    fmt = detect_transcript_format(data)
    raw_segments = []

    if fmt == "assemblyai":
        for utt in data.get("utterances", []):
            if utt.get("speaker") == speaker_label:
                start = utt.get("start", 0) / 1000.0  # ms to sec
                end = utt.get("end", 0) / 1000.0
                text = utt.get("text", "")
                raw_segments.append({"start": start, "end": end, "text": text})

    elif fmt == "speechmatics":
        current_start = None
        current_end = None
        current_text = []
        current_speaker = None

        for item in data.get("results", []):
            if item.get("type") != "word":
                continue

            # Get speaker - check alternatives first (speaker identification mode)
            speaker = item.get("speaker")
            content = ""
            alternatives = item.get("alternatives", [])
            if alternatives:
                if not speaker:
                    speaker = alternatives[0].get("speaker")
                content = alternatives[0].get("content", "")

            speaker = speaker or "UU"
            start = item.get("start_time", 0)
            end = item.get("end_time", 0)

            if speaker == speaker_label:
                if current_speaker != speaker_label:
                    # New segment starts
                    if current_start is not None:
                        raw_segments.append({
                            "start": current_start,
                            "end": current_end,
                            "text": " ".join(current_text),
                        })
                    current_start = start
                    current_text = []
                current_end = end
                current_speaker = speaker_label
                if content:
                    current_text.append(content)
            else:
                # Speaker changed
                if current_speaker == speaker_label and current_start is not None:
                    raw_segments.append({
                        "start": current_start,
                        "end": current_end,
                        "text": " ".join(current_text),
                    })
                    current_start = None
                    current_text = []
                current_speaker = speaker

        # Don't forget last segment
        if current_speaker == speaker_label and current_start is not None:
            raw_segments.append({
                "start": current_start,
                "end": current_end,
                "text": " ".join(current_text),
            })

    # Merge close segments and filter by duration
    merged = []
    for seg in raw_segments:
        duration = seg["end"] - seg["start"]
        if duration < min_duration:
            continue

        if merged and (seg["start"] - merged[-1]["end"]) <= max_gap:
            # Merge with previous
            merged[-1]["end"] = seg["end"]
            if seg["text"]:
                merged[-1]["text"] = (merged[-1]["text"] + " " + seg["text"]).strip()
        else:
            merged.append(seg)

    return merged


# ----------------------------------------------------------------------
# Audio Extraction
# ----------------------------------------------------------------------

def compute_b3sum(file_path: Path) -> str:
    """
    Compute blake3 hash of file contents using b3sum CLI.

    Returns first 32 chars (128 bits) for reasonable uniqueness.
    Falls back to sha256 if b3sum not available.
    """
    try:
        result = subprocess.run(
            ["b3sum", "--no-names", str(file_path)],
            capture_output=True,
            check=True,
            text=True,
        )
        # Return first 32 chars (128 bits) - plenty for uniqueness
        return result.stdout.strip()[:32]
    except (subprocess.CalledProcessError, FileNotFoundError):
        # Fallback to sha256 if b3sum not available
        h = hashlib.sha256()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(8192), b""):
                h.update(chunk)
        return h.hexdigest()[:32]


def extract_audio_segment(
    audio_path: Path,
    output_path: Path,
    start: float,
    end: float,
    format: str = "mp3",
) -> bool:
    """
    Extract audio segment using ffmpeg.

    Args:
        audio_path: Source audio file
        output_path: Output file path
        start: Start time in seconds
        end: End time in seconds
        format: Output format (mp3, wav)

    Returns:
        True if successful
    """
    duration = end - start

    cmd = [
        "ffmpeg", "-y",
        "-i", str(audio_path),
        "-ss", str(start),
        "-t", str(duration),
        "-ac", "1",  # mono
        "-ar", "16000",  # 16kHz
    ]

    if format == "mp3":
        cmd.extend(["-c:a", "libmp3lame", "-q:a", "2"])
    elif format == "wav":
        cmd.extend(["-c:a", "pcm_s16le"])

    cmd.append(str(output_path))

    try:
        result = subprocess.run(cmd, capture_output=True, check=True)
        return True
    except subprocess.CalledProcessError as e:
        print(f"ffmpeg error: {e.stderr.decode()}", file=sys.stderr)
        return False
    except FileNotFoundError:
        print("Error: ffmpeg not found. Please install ffmpeg.", file=sys.stderr)
        return False


def get_next_sample_id(speaker_dir: Path) -> str:
    """Get next available sample ID for a speaker."""
    existing = []
    for f in speaker_dir.glob("sample-*.mp3"):
        try:
            num = int(f.stem.split("-")[1])
            existing.append(num)
        except (ValueError, IndexError):
            pass
    for f in speaker_dir.glob("sample-*.wav"):
        try:
            num = int(f.stem.split("-")[1])
            existing.append(num)
        except (ValueError, IndexError):
            pass

    next_num = max(existing, default=0) + 1
    return f"sample-{next_num:03d}"


def write_metadata(
    meta_path: Path,
    sample_id: str,
    sample_b3sum: str,
    audio_path: Path,
    audio_b3sum: str,
    transcript_path: Optional[Path],
    segment: Dict[str, Any],
    speaker_label: str,
) -> None:
    """Write sample metadata YAML file (v2 schema with b3sum and review)."""
    meta = {
        "version": METADATA_VERSION,
        "sample_id": sample_id,
        "b3sum": sample_b3sum,  # Blake3 hash of THIS sample audio
        "source": {
            "audio_file": str(audio_path.resolve()),
            "audio_b3sum": audio_b3sum,  # Blake3 of source recording
        },
        "segment": {
            "speaker_label": speaker_label,
            "start_sec": segment["start"],
            "end_sec": segment["end"],
            "duration_sec": round(segment["end"] - segment["start"], 3),
            "text": segment.get("text", ""),
        },
        "extraction": {
            "tool": "speaker_samples",
            "tool_version": "1.1.0",
            "extracted_at": datetime.now(timezone.utc).isoformat(),
        },
        "review": {
            "status": "pending",  # pending | reviewed | rejected
            "reviewed_at": None,
            "notes": None,
        },
    }

    if transcript_path:
        meta["source"]["transcript_file"] = str(transcript_path.resolve())

    if YAML_AVAILABLE:
        with open(meta_path, "w") as f:
            yaml.dump(meta, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
    else:
        # Fallback to JSON if YAML not available
        with open(meta_path.with_suffix(".meta.json"), "w") as f:
            json.dump(meta, f, indent=2, ensure_ascii=False)


# ----------------------------------------------------------------------
# CLI Commands
# ----------------------------------------------------------------------

def cmd_extract(args) -> int:
    """Extract voice samples from audio using transcript."""
    audio_path = Path(args.audio)
    if not audio_path.exists():
        print(f"Error: Audio file not found: {audio_path}", file=sys.stderr)
        return 1

    # Load transcript
    transcript_path = Path(args.transcript)
    if not transcript_path.exists():
        print(f"Error: Transcript file not found: {transcript_path}", file=sys.stderr)
        return 1

    with open(transcript_path) as f:
        transcript_data = json.load(f)

    # Detect format
    fmt = detect_transcript_format(transcript_data)
    if fmt == "unknown":
        print("Error: Unknown transcript format. Supports AssemblyAI and Speechmatics.", file=sys.stderr)
        return 1

    # Check speaker label
    speaker_label = args.speaker_label
    available = get_available_speakers(transcript_data)

    if not speaker_label:
        print(f"Error: --speaker-label required. Available speakers: {', '.join(available)}", file=sys.stderr)
        return 1

    if speaker_label not in available:
        print(f"Warning: Speaker '{speaker_label}' not found. Available: {', '.join(available)}", file=sys.stderr)

    # Extract segments
    segments = extract_segments_from_transcript(
        transcript_data,
        speaker_label,
        min_duration=args.min_duration,
        max_gap=args.max_gap,
    )

    if not segments:
        print(f"No segments found for speaker '{speaker_label}'", file=sys.stderr)
        return 1

    total_duration = sum(s["end"] - s["start"] for s in segments)
    print(f"Found {len(segments)} segments for '{speaker_label}' ({total_duration:.1f}s total)", file=sys.stderr)

    # Apply limits
    if args.max_segments:
        segments = segments[:args.max_segments]
    if args.max_duration:
        filtered = []
        running = 0
        for seg in segments:
            dur = seg["end"] - seg["start"]
            if running + dur > args.max_duration:
                break
            filtered.append(seg)
            running += dur
        segments = filtered

    if not segments:
        print("No segments after filtering", file=sys.stderr)
        return 1

    # Setup output
    speaker_id = args.speaker_id
    speaker_dir = ensure_speaker_samples_dir(speaker_id)

    # Compute source audio b3sum once
    audio_b3sum = compute_b3sum(audio_path)

    # Extract each segment
    extracted = 0
    for seg in segments:
        sample_id = get_next_sample_id(speaker_dir)
        output_format = args.format or "mp3"
        output_path = speaker_dir / f"{sample_id}.{output_format}"
        meta_path = speaker_dir / f"{sample_id}.meta.yaml"

        if args.dry_run:
            print(f"Would extract: {sample_id} ({seg['start']:.2f}-{seg['end']:.2f}s)")
            continue

        if extract_audio_segment(audio_path, output_path, seg["start"], seg["end"], output_format):
            # Compute b3sum of extracted sample
            sample_b3sum = compute_b3sum(output_path)
            write_metadata(
                meta_path, sample_id, sample_b3sum,
                audio_path, audio_b3sum, transcript_path, seg, speaker_label
            )
            extracted += 1
            if args.verbose:
                print(f"Extracted: {sample_id} ({seg['start']:.2f}-{seg['end']:.2f}s) b3sum:{sample_b3sum[:8]}")
        else:
            print(f"Failed to extract segment {seg['start']:.2f}-{seg['end']:.2f}s", file=sys.stderr)

    if not args.dry_run:
        print(f"Extracted {extracted} samples to {speaker_dir}")

    return 0


def cmd_segments(args) -> int:
    """Output segment times as JSONL for piping."""
    # Load transcript
    transcript_path = Path(args.transcript)
    if not transcript_path.exists():
        print(f"Error: Transcript file not found: {transcript_path}", file=sys.stderr)
        return 1

    with open(transcript_path) as f:
        transcript_data = json.load(f)

    speaker_label = args.speaker_label
    available = get_available_speakers(transcript_data)

    if not speaker_label:
        print(f"Error: --speaker-label required. Available speakers: {', '.join(available)}", file=sys.stderr)
        return 1

    # Extract segments
    segments = extract_segments_from_transcript(
        transcript_data,
        speaker_label,
        min_duration=args.min_duration,
        max_gap=args.max_gap,
    )

    audio_path = args.audio
    speaker_id = args.speaker_id or "unknown"

    # Output as JSONL
    for seg in segments:
        record = {
            "speaker_id": speaker_id,
            "audio": str(audio_path) if audio_path else None,
            "start": seg["start"],
            "end": seg["end"],
            "text": seg.get("text", ""),
        }
        print(json.dumps(record))

    return 0


def cmd_list(args) -> int:
    """List stored samples."""
    samples_dir = get_samples_dir()

    if not samples_dir.exists():
        print("No samples found.")
        return 0

    if args.speaker_id:
        # List samples for specific speaker
        speaker_dir = samples_dir / args.speaker_id
        if not speaker_dir.exists():
            print(f"No samples found for speaker '{args.speaker_id}'")
            return 0

        samples = sorted(speaker_dir.glob("sample-*.mp3")) + sorted(speaker_dir.glob("sample-*.wav"))

        # Load metadata and optionally filter by status
        sample_data = []
        for sample in samples:
            meta_path = sample.with_suffix("").with_suffix(".meta.yaml")
            meta = load_sample_metadata(meta_path) or {}

            # Get review status
            review_status = meta.get("review", {}).get("status", "pending")

            # Filter by status if specified
            if args.status and review_status != args.status:
                continue

            sample_data.append({
                "path": sample,
                "meta": meta,
                "review_status": review_status,
            })

        # Apply pagination (offset and limit)
        if args.offset:
            sample_data = sample_data[args.offset:]
        if args.limit:
            sample_data = sample_data[:args.limit]

        if args.format == "json":
            output = []
            for item in sample_data:
                meta = item["meta"]
                entry = {
                    "sample_id": item["path"].stem,
                    "file": str(item["path"]),
                    "b3sum": meta.get("b3sum"),
                    "duration": meta.get("segment", {}).get("duration_sec"),
                    "text": meta.get("segment", {}).get("text", "")[:50],
                    "review_status": item["review_status"],
                }
                output.append(entry)
            print(json.dumps(output, indent=2))
        else:
            if not sample_data:
                status_msg = f" with status '{args.status}'" if args.status else ""
                print(f"No samples found for {args.speaker_id}{status_msg}")
                return 0

            print(f"Samples for {args.speaker_id}:")
            for item in sample_data:
                meta = item["meta"]
                duration = meta.get("segment", {}).get("duration_sec", 0)
                duration_str = f"{duration:.1f}s" if duration else "?"

                if args.show_review or args.status:
                    status = item["review_status"]
                    status_icon = {"pending": "○", "reviewed": "✓", "rejected": "✗"}.get(status, "?")
                    print(f"  {item['path'].stem}  {duration_str:>6}  {status_icon} {status}")
                else:
                    print(f"  {item['path'].stem}  {duration_str:>6}  {item['path'].suffix}")
    else:
        # List all speakers with sample counts
        speakers = []
        for speaker_path in sorted(samples_dir.iterdir()):
            if speaker_path.is_dir():
                samples = list(speaker_path.glob("sample-*.mp3")) + list(speaker_path.glob("sample-*.wav"))
                if samples:
                    total_dur = 0
                    counts = {"pending": 0, "reviewed": 0, "rejected": 0}
                    for sample in samples:
                        meta_path = sample.with_suffix("").with_suffix(".meta.yaml")
                        meta = load_sample_metadata(meta_path) or {}
                        total_dur += meta.get("segment", {}).get("duration_sec", 0)
                        status = meta.get("review", {}).get("status", "pending")
                        counts[status] = counts.get(status, 0) + 1

                    # Filter by status if specified
                    if args.status:
                        if counts.get(args.status, 0) == 0:
                            continue

                    speakers.append({
                        "id": speaker_path.name,
                        "count": len(samples),
                        "duration": total_dur,
                        "pending": counts["pending"],
                        "reviewed": counts["reviewed"],
                        "rejected": counts["rejected"],
                    })

        # Apply pagination (offset and limit)
        if args.offset:
            speakers = speakers[args.offset:]
        if args.limit:
            speakers = speakers[:args.limit]

        if args.format == "json":
            print(json.dumps(speakers, indent=2))
        else:
            if not speakers:
                print("No samples found.")
            else:
                if args.show_review:
                    print(f"{'Speaker':<16} {'Samples':>7} {'Duration':>9} {'Pending':>8} {'Reviewed':>8} {'Rejected':>8}")
                    print("-" * 65)
                    for s in speakers:
                        print(f"{s['id']:<16} {s['count']:>7} {s['duration']:>8.1f}s {s['pending']:>8} {s['reviewed']:>8} {s['rejected']:>8}")
                else:
                    print(f"{'Speaker':<20} {'Samples':>8} {'Duration':>10}")
                    print("-" * 40)
                    for s in speakers:
                        print(f"{s['id']:<20} {s['count']:>8} {s['duration']:>9.1f}s")

    return 0


def cmd_info(args) -> int:
    """Show sample metadata."""
    speaker_dir = get_speaker_samples_dir(args.speaker_id)

    # Find sample
    sample_path = None
    for ext in [".mp3", ".wav"]:
        candidate = speaker_dir / f"{args.sample_id}{ext}"
        if candidate.exists():
            sample_path = candidate
            break

    if not sample_path:
        print(f"Error: Sample '{args.sample_id}' not found for speaker '{args.speaker_id}'", file=sys.stderr)
        return 1

    # Load metadata
    meta_path = sample_path.with_suffix("").with_suffix(".meta.yaml")
    if meta_path.exists() and YAML_AVAILABLE:
        with open(meta_path) as f:
            meta = yaml.safe_load(f)
        if args.format == "json":
            print(json.dumps(meta, indent=2, default=str))
        else:
            print(yaml.dump(meta, default_flow_style=False, allow_unicode=True))
    else:
        # Try JSON fallback
        meta_json = sample_path.with_suffix("").with_suffix(".meta.json")
        if meta_json.exists():
            with open(meta_json) as f:
                meta = json.load(f)
            print(json.dumps(meta, indent=2, default=str))
        else:
            print(f"No metadata found for sample '{args.sample_id}'")
            return 1

    return 0


def cmd_remove(args) -> int:
    """Remove samples."""
    speaker_dir = get_speaker_samples_dir(args.speaker_id)

    if not speaker_dir.exists():
        print(f"No samples found for speaker '{args.speaker_id}'")
        return 0

    samples = sorted(speaker_dir.glob("sample-*.mp3")) + sorted(speaker_dir.glob("sample-*.wav"))

    if not samples:
        print(f"No samples found for speaker '{args.speaker_id}'")
        return 0

    to_remove = []

    if args.all:
        to_remove = samples
    elif args.source:
        # Filter by source pattern
        for sample in samples:
            meta_path = sample.with_suffix("").with_suffix(".meta.yaml")
            if meta_path.exists() and YAML_AVAILABLE:
                with open(meta_path) as f:
                    meta = yaml.safe_load(f)
                source = meta.get("source", {}).get("audio_file", "")
                if args.source in source:
                    to_remove.append(sample)
    elif args.sample_id:
        for sample in samples:
            if sample.stem == args.sample_id:
                to_remove.append(sample)
                break
    else:
        print("Error: Specify --all, --source, or sample_id", file=sys.stderr)
        return 1

    if not to_remove:
        print("No matching samples found.")
        return 0

    # Dry-run mode: show what would be removed
    if getattr(args, "dry_run", False):
        print(f"Would remove {len(to_remove)} samples:")
        for sample in to_remove:
            print(f"  {sample.stem}")
            meta_path = sample.with_suffix("").with_suffix(".meta.yaml")
            if meta_path.exists():
                print(f"    + {meta_path.name}")
        return 0

    if not args.force:
        print(f"Will remove {len(to_remove)} samples:")
        for s in to_remove[:5]:
            print(f"  {s.stem}")
        if len(to_remove) > 5:
            print(f"  ... and {len(to_remove) - 5} more")
        response = input("Continue? [y/N] ")
        if response.lower() != "y":
            print("Cancelled.")
            return 0

    removed = 0
    for sample in to_remove:
        sample.unlink()
        # Remove metadata
        for meta_ext in [".meta.yaml", ".meta.json"]:
            meta_path = sample.with_suffix("").with_suffix(meta_ext)
            if meta_path.exists():
                meta_path.unlink()
        removed += 1

    if not getattr(args, "quiet", False):
        print(f"Removed {removed} samples")

    # Remove empty directory
    if not any(speaker_dir.iterdir()):
        speaker_dir.rmdir()

    return 0


def cmd_speakers(args) -> int:
    """List available speakers in transcript."""
    transcript_path = Path(args.transcript)
    if not transcript_path.exists():
        print(f"Error: Transcript file not found: {transcript_path}", file=sys.stderr)
        return 1

    with open(transcript_path) as f:
        transcript_data = json.load(f)

    fmt = detect_transcript_format(transcript_data)
    speakers = get_available_speakers(transcript_data)

    print(f"Format: {fmt}")
    print(f"Speakers: {', '.join(speakers) if speakers else 'none'}")

    return 0


def load_sample_metadata(meta_path: Path) -> Optional[Dict[str, Any]]:
    """Load sample metadata, handling both YAML and JSON formats."""
    if meta_path.exists() and YAML_AVAILABLE:
        with open(meta_path) as f:
            return yaml.safe_load(f)
    # Try JSON fallback
    json_path = meta_path.with_suffix(".json")
    if json_path.exists():
        with open(json_path) as f:
            return json.load(f)
    return None


def save_sample_metadata(meta_path: Path, meta: Dict[str, Any]) -> None:
    """Save sample metadata to YAML (or JSON fallback)."""
    if YAML_AVAILABLE:
        with open(meta_path, "w") as f:
            yaml.dump(meta, f, default_flow_style=False, allow_unicode=True, sort_keys=False)
    else:
        with open(meta_path.with_suffix(".json"), "w") as f:
            json.dump(meta, f, indent=2, ensure_ascii=False)


def cmd_review(args) -> int:
    """Review samples - approve or reject."""
    speaker_dir = get_speaker_samples_dir(args.speaker_id)

    if not speaker_dir.exists():
        print(f"Error: No samples found for speaker '{args.speaker_id}'", file=sys.stderr)
        return 1

    # Find samples to review
    samples_to_review = []

    if args.sample_id:
        # Single sample
        for ext in [".mp3", ".wav"]:
            sample_path = speaker_dir / f"{args.sample_id}{ext}"
            if sample_path.exists():
                samples_to_review.append(sample_path)
                break
        if not samples_to_review:
            print(f"Error: Sample '{args.sample_id}' not found", file=sys.stderr)
            return 1
    elif args.source_b3sum:
        # All samples from a specific source recording
        all_samples = list(speaker_dir.glob("sample-*.mp3")) + list(speaker_dir.glob("sample-*.wav"))
        for sample in all_samples:
            meta_path = sample.with_suffix("").with_suffix(".meta.yaml")
            meta = load_sample_metadata(meta_path)
            if meta and meta.get("source", {}).get("audio_b3sum", "").startswith(args.source_b3sum):
                samples_to_review.append(sample)
        if not samples_to_review:
            print(f"Error: No samples found from source b3sum '{args.source_b3sum}'", file=sys.stderr)
            return 1
    else:
        print("Error: Specify sample_id or --source-b3sum", file=sys.stderr)
        return 1

    # Determine new status
    if args.approve:
        new_status = "reviewed"
    elif args.reject:
        new_status = "rejected"
    else:
        print("Error: Specify --approve or --reject", file=sys.stderr)
        return 1

    # Update each sample
    updated = 0
    for sample_path in samples_to_review:
        meta_path = sample_path.with_suffix("").with_suffix(".meta.yaml")
        meta = load_sample_metadata(meta_path)

        if not meta:
            print(f"Warning: No metadata for {sample_path.stem}", file=sys.stderr)
            continue

        # Ensure review section exists (for v1 samples)
        if "review" not in meta:
            meta["review"] = {"status": "pending", "reviewed_at": None, "notes": None}

        old_status = meta["review"].get("status", "pending")
        meta["review"]["status"] = new_status
        meta["review"]["reviewed_at"] = datetime.now(timezone.utc).isoformat()
        if args.notes:
            meta["review"]["notes"] = args.notes

        # Update version if needed
        if meta.get("version", 1) < 2:
            meta["version"] = 2

        save_sample_metadata(meta_path, meta)
        updated += 1

        if len(samples_to_review) == 1 or args.verbose:
            print(f"{sample_path.stem}: {old_status} -> {new_status}")

    if len(samples_to_review) > 1 and not args.verbose:
        print(f"Updated {updated} samples to '{new_status}'")

    return 0


# ----------------------------------------------------------------------
# Main
# ----------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(
        description="Voice sample extraction and management",
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )
    # Global options
    parser.add_argument("-q", "--quiet", action="store_true",
                        help="Suppress status messages (still outputs data)")

    subparsers = parser.add_subparsers(dest="command", required=True)

    # extract command
    extract_parser = subparsers.add_parser("extract", help="Extract samples from audio")
    extract_parser.add_argument("audio", help="Audio file path")
    extract_parser.add_argument("-t", "--transcript", required=True, help="Transcript JSON file")
    extract_parser.add_argument("-l", "--speaker-label", required=True, help="Speaker label in transcript")
    extract_parser.add_argument("-s", "--speaker-id", required=True, help="Target speaker ID for storage")
    extract_parser.add_argument("--format", choices=["mp3", "wav"], default="mp3", help="Output format")
    extract_parser.add_argument("--min-duration", type=float, default=0.5, help="Minimum segment duration (sec)")
    extract_parser.add_argument("--max-gap", type=float, default=1.0, help="Max gap to merge segments (sec)")
    extract_parser.add_argument("--max-segments", type=int, help="Maximum segments to extract")
    extract_parser.add_argument("--max-duration", type=float, help="Maximum total duration (sec)")
    extract_parser.add_argument("-n", "--dry-run", action="store_true", help="Show what would be extracted")
    extract_parser.add_argument("-v", "--verbose", action="store_true", help="Verbose output")
    extract_parser.set_defaults(func=cmd_extract)

    # segments command
    seg_parser = subparsers.add_parser("segments", help="Output segment times as JSONL")
    seg_parser.add_argument("--transcript", "-t", required=True, help="Transcript JSON file")
    seg_parser.add_argument("--speaker-label", "-l", required=True, help="Speaker label")
    seg_parser.add_argument("--speaker-id", "-s", help="Speaker ID for output")
    seg_parser.add_argument("--audio", "-a", help="Audio file path (for output)")
    seg_parser.add_argument("--min-duration", type=float, default=0.5, help="Minimum segment duration")
    seg_parser.add_argument("--max-gap", type=float, default=1.0, help="Max gap to merge")
    seg_parser.set_defaults(func=cmd_segments)

    # list command
    list_parser = subparsers.add_parser("list", help="List stored samples")
    list_parser.add_argument("speaker_id", nargs="?", help="Speaker ID (optional)")
    list_parser.add_argument("--format", choices=["table", "json"], default="table", help="Output format")
    list_parser.add_argument("--show-review", action="store_true", help="Show review status")
    list_parser.add_argument("--status", choices=["pending", "reviewed", "rejected"], help="Filter by review status")
    list_parser.add_argument("--limit", type=int, help="Maximum number of results to display")
    list_parser.add_argument("--offset", type=int, default=0, help="Skip first N results (for pagination)")
    list_parser.set_defaults(func=cmd_list)

    # info command
    info_parser = subparsers.add_parser("info", help="Show sample metadata")
    info_parser.add_argument("speaker_id", help="Speaker ID")
    info_parser.add_argument("sample_id", help="Sample ID")
    info_parser.add_argument("--format", choices=["yaml", "json"], default="yaml", help="Output format")
    info_parser.set_defaults(func=cmd_info)

    # remove command
    remove_parser = subparsers.add_parser("remove", help="Remove samples")
    remove_parser.add_argument("speaker_id", help="Speaker ID")
    remove_parser.add_argument("sample_id", nargs="?", help="Sample ID to remove")
    remove_parser.add_argument("--all", action="store_true", help="Remove all samples")
    remove_parser.add_argument("--source", help="Remove samples from matching source path")
    remove_parser.add_argument("-f", "--force", action="store_true", help="Skip confirmation")
    remove_parser.add_argument("-n", "--dry-run", action="store_true", help="Show what would be removed")
    remove_parser.set_defaults(func=cmd_remove)

    # speakers command (utility to inspect transcript)
    speakers_parser = subparsers.add_parser("speakers", help="List speakers in transcript")
    speakers_parser.add_argument("transcript", help="Transcript JSON file")
    speakers_parser.set_defaults(func=cmd_speakers)

    # review command
    review_parser = subparsers.add_parser("review", help="Review samples (approve/reject)")
    review_parser.add_argument("speaker_id", help="Speaker ID")
    review_parser.add_argument("sample_id", nargs="?", help="Sample ID to review")
    review_parser.add_argument("--source-b3sum", help="Review all samples from source with this b3sum prefix")
    review_parser.add_argument("--approve", action="store_true", help="Mark as reviewed/approved")
    review_parser.add_argument("--reject", action="store_true", help="Mark as rejected")
    review_parser.add_argument("--notes", help="Review notes")
    review_parser.add_argument("-v", "--verbose", action="store_true", help="Verbose output")
    review_parser.set_defaults(func=cmd_review)

    args = parser.parse_args()
    return args.func(args)


if __name__ == "__main__":
    sys.exit(main())
